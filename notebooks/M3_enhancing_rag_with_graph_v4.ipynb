{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2763224591/work_public/blob/main/notebooks/M3_enhancing_rag_with_graph_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enhancing RAG-based Applications with Knowledge Graphs\n",
        "\n",
        "## A Practical Guide to Constructing and Leveraging Knowledge Graphs in RAG Applications with Neo4j and LangChain"
      ],
      "metadata": {
        "id": "-KeAfaMQ0VKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "利用知识图谱增强基于RAG的应用\n",
        "\n",
        "使用Neo4j和LangChain在RAG应用中构建与利用知识图谱的实用指南"
      ],
      "metadata": {
        "id": "D64a5eFa5wTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph retrieval-augmented generation (Graph RAG) is emerging as a powerful enhancement to traditional vector search methods in RAG-based applications. By combining the power of graph databases and vector-based approaches, you can achieve more accurate, context-rich results.\n",
        "\n",
        "Graph databases store data as nodes and relationships, representing complex and interconnected information in a structured way. This makes them highly effective for capturing intricate relationships and attributes across diverse data types. On the other hand, vector databases excel at managing unstructured data by converting it into high-dimensional vectors, making it easier to search for semantic similarities. Integrating these two approaches allows RAG applications to leverage the strengths of both graph and vector databases, which we demonstrate in this tutorial."
      ],
      "metadata": {
        "id": "pCmW2CCHyZzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "知识图谱增强检索（Graph RAG）正成为基于RAG应用中传统向量搜索方法的重要升级。通过结合图数据库与向量技术的优势，开发者能够获得更精准且富含上下文信息的结果。\n",
        "\n",
        "图数据库将数据存储为节点（实体）​和关系（连接）​，以结构化方式呈现复杂的关联信息。这种特性使其在捕获跨数据类型的复杂关联与属性特征时具有显著优势。而向量数据库擅长处理非结构化数据，通过将其转化为高维向量空间中的数学表示，实现对语义相似性的高效检索。\n",
        "\n",
        "本教程将演示如何融合这两种技术，使RAG应用同时发挥图数据库的关系推理能力与向量数据库的语义理解能力，形成更强大的混合检索架构。"
      ],
      "metadata": {
        "id": "NHERW7AH5rAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "- **Neo4j**: Set up a Neo4j database instance, either using the free Neo4j Aura cloud service or by installing Neo4j Desktop locally.\n",
        "- **OpenAI API Key**: Obtain an OpenAI API key to access the models we use in this tutorial.\n",
        "- **LangChain, Neo4j, and other dependencies**: Install the necessary Python packages."
      ],
      "metadata": {
        "id": "OvRfyUErykIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "环境准备\n",
        "\n",
        "​Neo4j图数据库​\n",
        "▸ 云端部署：使用免费的Neo4j Aura云服务\n",
        "▸ 本地部署：安装Neo4j Desktop客户端\n",
        "\n",
        "​OpenAI API密钥​\n",
        "▸ 申请OpenAI API密钥（用于访问本教程所需的大模型）"
      ],
      "metadata": {
        "id": "atn9D5sh7LCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and run this command to install the necessary packages\n",
        "!pip install --upgrade --quiet langchain langchain-community langchain-openai langchain-experimental neo4j wikipedia tiktoken yfiles_jupyter_graphs PyPDF2 pypdf"
      ],
      "metadata": {
        "id": "bW3UfefsyoWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPIRSGz4tHNV"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import (\n",
        "    RunnableBranch,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Tuple, List, Optional\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.document_loaders import WikipediaLoader\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from yfiles_jupyter_graphs import GraphWidget\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up Environment Variables\n",
        "\n",
        "You'll need to set up environment variables for your OpenAI API key and Neo4j credentials. Add the following lines to your code to configure them:"
      ],
      "metadata": {
        "id": "HXtapRkOytxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "环境变量配置\n",
        "\n",
        "需为OpenAI API密钥及Neo4j数据库凭证设置环境变量，通过以下代码进行配置："
      ],
      "metadata": {
        "id": "hQOMNZCc7XVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0nXP1aYtHNW"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"NEO4J_URI\"] = \"neo4j+s://fae385d3.databases.neo4j.io\"\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"\"\n",
        "\n",
        "graph = Neo4jGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Ingestion and Knowledge Graph Construction\n",
        "\n",
        "In this tutorial, we will use an academic research paper (for example, an \"attention mechanism\" paper) as our data source. We will ingest the text and construct a knowledge graph using LangChain and Neo4j."
      ],
      "metadata": {
        "id": "GHKExwYntyD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "数据摄取与知识图谱构建\n",
        "\n",
        "本教程将采用学术研究论文（例如关于\"注意力机制\"的论文）作为数据源，基于LangChain与Neo4j实现文本数据摄取及知识图谱构建。"
      ],
      "metadata": {
        "id": "V0H0jvTU7bz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Replace 'path/to/your/document.pdf' with the actual path to your PDF file\n",
        "pdf_path = \"/content/attention.pdf\"\n",
        "\n",
        "# Initialize the loader with the PDF path\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "\n",
        "# Load the documents\n",
        "raw_documents = loader.load()"
      ],
      "metadata": {
        "id": "RXcbmJMWW0ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the Document into Chunks"
      ],
      "metadata": {
        "id": "eVThCn4Py3CO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "文档分块处理"
      ],
      "metadata": {
        "id": "qm4tVnjx7f9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGhtLTAStHNW"
      },
      "outputs": [],
      "source": [
        "# Define chunking strategy\n",
        "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
        "documents = text_splitter.split_documents(raw_documents[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to construct a graph based on the retrieved documents. For this purpose, we have implemented an `LLMGraphTransformermodule` that significantly simplifies constructing and storing a knowledge graph in a graph database."
      ],
      "metadata": {
        "id": "kphZMjjVuGAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "知识图谱构建阶段\n",
        "\n",
        "基于检索文档构建图谱的时机已到。为此我们实现了LLMGraphTransformer模块，该模块可显著简化在图数据库中构建及存储知识图谱的流程。"
      ],
      "metadata": {
        "id": "gbTq8KRa7pAf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXf7OTGHtHNW"
      },
      "outputs": [],
      "source": [
        "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\") # gpt-4-0125-preview occasionally has issues\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    baseEntityLabel=True,\n",
        "    include_source=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Note that the quality of the generated graph largely depends on the model used—ideally, you should select the most capable model. The LLM graph transformers generate graph documents, which can be imported into Neo4j using the `add_graph_documents` method. The `baseEntityLabel` parameter adds an `__Entity__` label to each node, enhancing indexing and query performance. Additionally, the `include_source` parameter helps link nodes to their source documents, supporting data traceability and context.\n"
      ],
      "metadata": {
        "id": "ll2asQiAugSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "请注意，生成的图的质量很大程度上取决于所使用的模型——理想情况下，您应该选择性能最强的模型。LLM 图转换器会生成图文档，您可以使用 add_graph_documents 方法将其导入 Neo4j。baseEntityLabel 参数会为每个节点添加 __Entity__ 标签，从而增强索引和查询性能。此外，include_source 参数有助于将节点链接到其源文档，从而支持数据可追溯性和上下文关联。"
      ],
      "metadata": {
        "id": "DaWhpJEi79RZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing and Visualizing the Knowledge Graph in Neo4j"
      ],
      "metadata": {
        "id": "1MUpOp4lzChf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在Neo4j中构建与可视化知识图谱"
      ],
      "metadata": {
        "id": "-DIXjDHu8lLu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMZlhtDmtHNW"
      },
      "outputs": [],
      "source": [
        "# directly show the graph resulting from the given Cypher query\n",
        "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n",
        "\n",
        "def showGraph(cypher: str = default_cypher):\n",
        "    # create a neo4j session to run queries\n",
        "    driver = GraphDatabase.driver(\n",
        "        uri = os.environ[\"NEO4J_URI\"],\n",
        "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
        "                os.environ[\"NEO4J_PASSWORD\"]))\n",
        "    session = driver.session()\n",
        "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
        "    widget.node_label_mapping = 'id'\n",
        "    #display(widget)\n",
        "    return widget\n",
        "\n",
        "showGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hybrid Retrieval for RAG\n",
        "\n",
        "After generating the knowledge graph, we will implement a hybrid retrieval approach that combines vector and keyword indexes with graph retrieval for RAG applications.\n",
        "\n",
        "![retrieval](https://raw.githubusercontent.com/tomasonjo/blogs/master/graphhybrid.png)\n",
        "\n",
        "The diagram illustrates a retrieval process beginning with a user posing a question, which is then directed to an RAG retriever. This retriever employs keyword and vector searches to search through unstructured text data and combines it with the information it collects from the knowledge graph. Since Neo4j features both keyword and vector indexes, you can implement all three retrieval options with a single database system. The collected data from these sources is fed into an LLM to generate and deliver the final answer.\n",
        "## Unstructured data retriever\n",
        "You can use the Neo4jVector.from_existing_graph method to add both keyword and vector retrieval to documents. This method configures keyword and vector search indexes for a hybrid search approach, targeting nodes labeled Document. Additionally, it calculates text embedding values if they are missing.\n"
      ],
      "metadata": {
        "id": "1guHjU4uyEZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG混合检索机制​\n",
        "\n",
        "完成知识图谱构建后，我们将实施融合向量索引、关键词索引与图谱检索的混合检索方案，专用于RAG应用场景。\n",
        "\n",
        "该示意图展示了检索流程：用户提出问题后，问题被导向RAG检索器。该检索器通过关键词搜索和向量搜索遍历非结构化文本数据，并将其与从知识图谱收集的信息相结合。由于Neo4j同时具备关键词索引和向量索引功能，您可在单一数据库系统中实现全部三种检索方式。收集到的数据输入大语言模型（LLM），最终生成并输出答案。\n",
        "\n",
        "​非结构化数据检索器​\n",
        "\n",
        "您可使用Neo4jVector.from_existing_graph方法为文档添加关键词检索和向量检索功能。该方法通过配置关键词搜索索引和向量搜索索引实现混合检索方案，目标节点标记为Document。此外，若文本嵌入值缺失，该方法将自动计算生成。"
      ],
      "metadata": {
        "id": "AuBDE3_e9CyX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHbJPMfDtHNW"
      },
      "outputs": [],
      "source": [
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(),\n",
        "    search_type=\"hybrid\",\n",
        "    node_label=\"Document\",\n",
        "    text_node_properties=[\"text\"],\n",
        "    embedding_node_property=\"embedding\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vector index can then be called with the similarity_search method.\n",
        "\n",
        "### Graph retriever\n",
        "Configuring graph retrieval, on the other hand, is more complex but provides greater flexibility. In this example, we will use a full-text index to locate relevant nodes and then retrieve their immediate neighbors.\n",
        "\n",
        "\n",
        "![graph](https://raw.githubusercontent.com/tomasonjo/blogs/master/neighbor.png)\n",
        "\n",
        "The graph retriever begins by identifying relevant entities in the input. For simplicity, we instruct the LLM to identify people, organizations, and locations. To do this, we will utilize LCEL with the newly introduced `with_structured_output` method.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2nzfPwvvy0Yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "向量索引可通过similarity_search方法调用。\n",
        "\n",
        "图谱检索器\n",
        "\n",
        "相较而言，图谱检索的配置更为复杂，但灵活性更高。本例中，我们将使用全文索引定位相关节点，继而检索其直接相邻节点。\n",
        "\n",
        "图谱检索器首先识别输入中的相关实体。为简化流程，我们指示大语言模型（LLM）专门识别人物、组织及地点三类实体。为实现此功能，我们将采用LCEL（LangChain表达式语言）结合新引入的with_structured_output结构化输出方法。"
      ],
      "metadata": {
        "id": "Q-4cbLCx9UxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yCMz_sRtHNW"
      },
      "outputs": [],
      "source": [
        "# Retriever\n",
        "\n",
        "graph.query(\n",
        "    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
        "\n",
        "# Extract entities from text\n",
        "class Entities(BaseModel):\n",
        "    \"\"\"Identifying information about entities.\"\"\"\n",
        "\n",
        "    names: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"All the person, organization, or business entities that \"\n",
        "        \"appear in the text\",\n",
        "    )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting organization and person entities from the text.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following \"\n",
        "            \"input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "entity_chain = prompt | llm.with_structured_output(Entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it out:"
      ],
      "metadata": {
        "id": "n-Cs7RFAzdT3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54H15KNAtHNX",
        "outputId": "ec6bed69-c34b-40c3-ac94-c98ac6c9fe41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Transformer', 'multi-head attention']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "entity_chain.invoke({\"question\": \"Which component in the Transformer uses multi-head attention?\"}).names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now that we can detect entities in the question, let's use a full-text index to map them to the knowledge graph. First, we need to define a full-text index and a function that will generate full-text queries that allow a bit of misspelling, which we won't go into much detail here."
      ],
      "metadata": {
        "id": "e2S2aWq5zfQO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY8huoM8tHNX"
      },
      "outputs": [],
      "source": [
        "def generate_full_text_query(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a full-text search query for a given input string.\n",
        "\n",
        "    This function constructs a query string suitable for a full-text search.\n",
        "    It processes the input string by splitting it into words and appending a\n",
        "    similarity threshold (~2 changed characters) to each word, then combines\n",
        "    them using the AND operator. Useful for mapping entities from user questions\n",
        "    to database values, and allows for some misspelings.\n",
        "    \"\"\"\n",
        "    full_text_query = \"\"\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    for word in words[:-1]:\n",
        "        full_text_query += f\" {word}~2 AND\"\n",
        "    full_text_query += f\" {words[-1]}~2\"\n",
        "    return full_text_query.strip()\n",
        "\n",
        "# Fulltext index query\n",
        "def structured_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke({\"question\": question})\n",
        "    for entity in entities.names:\n",
        "        response = graph.query(\n",
        "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
        "            YIELD node,score\n",
        "            CALL {\n",
        "              WITH node\n",
        "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
        "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
        "              UNION ALL\n",
        "              WITH node\n",
        "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
        "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
        "            }\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": generate_full_text_query(entity)},\n",
        "        )\n",
        "        result += \"\\n\".join([el['output'] for el in response])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `structured_retriever` function starts by detecting entities in the user question. Next, it iterates over the detected entities and uses a Cypher template to retrieve the neighborhood of relevant nodes. Let's test it out!"
      ],
      "metadata": {
        "id": "g-F9BjghzjdH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6fOJRPntHNX"
      },
      "outputs": [],
      "source": [
        "print(structured_retriever(\"Which component in the Transformer uses multi-head attention?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final retriever\n",
        "As we mentioned at the start, we'll combine the unstructured and graph retriever to create the final context that will be passed to an LLM."
      ],
      "metadata": {
        "id": "xN9c_dEozyaO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCTMp3prtHNX"
      },
      "outputs": [],
      "source": [
        "def retriever(question: str):\n",
        "    print(f\"Search query: {question}\")\n",
        "    structured_data = structured_retriever(question)\n",
        "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
        "    final_data = f\"\"\"Structured data:\n",
        "{structured_data}\n",
        "Unstructured data:\n",
        "{\"#Document \". join(unstructured_data)}\n",
        "    \"\"\"\n",
        "    return final_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are dealing with Python, we can simply concatenate the outputs using the f-string.\n",
        "## Defining the RAG chain\n",
        "We have successfully implemented the retrieval component of the RAG. First, we will introduce the query rewriting part that allows conversational follow up questions.\n"
      ],
      "metadata": {
        "id": "NZG9Q8Ohz3Hn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu68Z79ttHNX"
      },
      "outputs": [],
      "source": [
        "# Condense a chat history and follow-up question into a standalone question\n",
        "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
        "in its original language.\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"  # noqa: E501\n",
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
        "\n",
        "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
        "    buffer = []\n",
        "    for human, ai in chat_history:\n",
        "        buffer.append(HumanMessage(content=human))\n",
        "        buffer.append(AIMessage(content=ai))\n",
        "    return buffer\n",
        "\n",
        "_search_query = RunnableBranch(\n",
        "    # If input includes chat_history, we condense it with the follow-up question\n",
        "    (\n",
        "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
        "            run_name=\"HasChatHistoryCheck\"\n",
        "        ),  # Condense follow-up question and chat into a standalone_question\n",
        "        RunnablePassthrough.assign(\n",
        "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
        "        )\n",
        "        | CONDENSE_QUESTION_PROMPT\n",
        "        | ChatOpenAI(temperature=0)\n",
        "        | StrOutputParser(),\n",
        "    ),\n",
        "    # Else, we have no chat history, so just pass through the question\n",
        "    RunnableLambda(lambda x : x[\"question\"]),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we introduce a prompt that leverages the context provided by the integrated hybrid retriever to produce the response, completing the implementation of the RAG chain."
      ],
      "metadata": {
        "id": "CsH90hbvz_aF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzb2jcittHNY"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Use natural language and be concise.\n",
        "Answer:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"context\": _search_query | retriever,\n",
        "            \"question\": RunnablePassthrough(),\n",
        "        }\n",
        "    )\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can go ahead and test our hybrid RAG implementation."
      ],
      "metadata": {
        "id": "w3SeRw0L0Gy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtU0iMNgtHNY",
        "outputId": "456f54bf-42a3-4af2-8805-ff3a01c1d5f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search query: Which component in the Transformer uses multi-head attention?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The encoder and decoder components in the Transformer use multi-head attention.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"Which component in the Transformer uses multi-head attention?\"})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}